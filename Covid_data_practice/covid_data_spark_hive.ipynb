{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***@Author: Ranjith G C**\n",
    "<br>\n",
    "***@Date: 2021-09-30***\n",
    "<br>\n",
    "***@Last Modified by: Ranjith G C***\n",
    "<br>\n",
    "***@Last Modified time: 2021-09-30***\n",
    "<br>\n",
    "***@Title : Program Aim to practice on covid dataset using spark sql operations.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").appName('covid_data').getOrCreate()\n",
    "sc=spark.sparkContext\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import col, max as max_, min as min_, unix_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"hdfs://localhost:9000/covid/*.csv\")\n",
    "df.createOrReplaceTempView(\"ranjith\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dispaly State and Active Cases in which they have greater than 1000 cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|            State|Active|\n",
      "+-----------------+------+\n",
      "|   Andhra Pradesh| 14388|\n",
      "|            Assam|  4984|\n",
      "| Himachal Pradesh|  1616|\n",
      "|Jammu and Kashmir|  1461|\n",
      "|        Karnataka| 14386|\n",
      "|           Kerala|167578|\n",
      "|      Maharashtra| 45229|\n",
      "|          Manipur|  2183|\n",
      "|        Meghalaya|  1896|\n",
      "|          Mizoram| 15140|\n",
      "|           Odisha|  4947|\n",
      "|       Tamil Nadu| 16984|\n",
      "|        Telengana|  4991|\n",
      "|      West Bengal|  7810|\n",
      "+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "where = spark.sql(\"select State,Active from ranjith where active >= 1000\")\n",
    "where.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display State and Death ratio in between 0.0 to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|               State|DeathRatio|\n",
      "+--------------------+----------+\n",
      "|      Andhra Pradesh|      0.69|\n",
      "|   Arunachal Pradesh|       0.5|\n",
      "|               Assam|      0.97|\n",
      "|Dadra and Nagar H...|      0.04|\n",
      "|              Kerala|      0.52|\n",
      "|              Ladakh|       1.0|\n",
      "|         Lakshadweep|      0.49|\n",
      "|             Mizoram|      0.32|\n",
      "|              Odisha|       0.8|\n",
      "|           Rajasthan|      0.94|\n",
      "|           Telengana|      0.59|\n",
      "|             Tripura|      0.96|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Death_ratio = spark.sql(\"select State, DeathRatio from ranjith where DeathRatio >= 0.00 and DeathRatio <= 1.00\")\n",
    "Death_ratio.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the sum of Active Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|sum(CAST(Active AS DOUBLE))|\n",
      "+---------------------------+\n",
      "|                   309575.0|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total = spark.sql(\"select sum(Active) from ranjith\")\n",
    "total.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the Average Discharge Ratio in all states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+\n",
      "|avg(CAST(DischargeRatio AS DOUBLE))|\n",
      "+-----------------------------------+\n",
      "|                  97.62027777777776|\n",
      "+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "average = spark.sql(\"select avg(DischargeRatio) from ranjith\")\n",
    "average.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the Average Death Ratio in all states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|avg(CAST(DeathRatio AS DOUBLE))|\n",
      "+-------------------------------+\n",
      "|             1.2672222222222222|\n",
      "+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "average = spark.sql(\"select avg(DeathRatio) from ranjith\")\n",
    "average.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the sum of Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|sum(CAST(Deaths AS DOUBLE))|\n",
      "+---------------------------+\n",
      "|                   445385.0|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total = spark.sql(\"select sum(Deaths) from ranjith\")\n",
    "total.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving covid data into hive table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName('covid_data').enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hive1 = df.select(\"State\",\"TotalCases\",\"Active\",\"Discharged\",\"Deaths\",\"ActiveRatio\",\"DischargeRatio\",\"DeathRatio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hive1.write.mode(\"overwrite\").saveAsTable(\"default.covid_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------+----------+------+-----------+--------------+----------+\n",
      "|               State|TotalCases|Active|Discharged|Deaths|ActiveRatio|DischargeRatio|DeathRatio|\n",
      "+--------------------+----------+------+----------+------+-----------+--------------+----------+\n",
      "| Andaman and Nicobar|      7600|    13|      7458|   129|       0.17|         98.13|       1.7|\n",
      "|      Andhra Pradesh|   2039529| 14388|   2011063| 14078|       0.71|          98.6|      0.69|\n",
      "|   Arunachal Pradesh|     54126|   410|     53444|   272|       0.76|         98.74|       0.5|\n",
      "|               Assam|    598423|  4984|    587632|  5807|       0.83|          98.2|      0.97|\n",
      "|               Bihar|    725901|    69|    716173|  9659|       0.01|         98.66|      1.33|\n",
      "|          Chandigarh|     65188|    41|     64329|   818|       0.06|         98.68|      1.25|\n",
      "|        Chhattisgarh|   1005094|   297|    991234| 13563|       0.03|         98.62|      1.35|\n",
      "|Dadra and Nagar H...|     10670|     0|     10666|     4|        0.0|         99.96|      0.04|\n",
      "|               Delhi|   1438517|   379|   1413053| 25085|       0.03|         98.23|      1.74|\n",
      "|                 Goa|    175583|   810|    171478|  3295|       0.46|         97.66|      1.88|\n",
      "|             Gujarat|    825737|   133|    815522| 10082|       0.02|         98.76|      1.22|\n",
      "|             Haryana|    770746|   340|    760598|  9808|       0.04|         98.68|      1.27|\n",
      "|    Himachal Pradesh|    217140|  1616|    211871|  3653|       0.74|         97.57|      1.68|\n",
      "|   Jammu and Kashmir|    328069|  1461|    322191|  4417|       0.45|         98.21|      1.35|\n",
      "|           Jharkhand|    348125|    55|    342937|  5133|       0.02|         98.51|      1.47|\n",
      "|           Karnataka|   2968543| 14386|   2916530| 37627|       0.48|         98.25|      1.27|\n",
      "|              Kerala|   4524158|167578|   4332897| 23683|        3.7|         95.77|      0.52|\n",
      "|              Ladakh|     20737|   138|     20392|   207|       0.67|         98.34|       1.0|\n",
      "|         Lakshadweep|     10359|     8|     10300|    51|       0.08|         99.43|      0.49|\n",
      "|      Madhya Pradesh|    792402|    96|    781789| 10517|       0.01|         98.66|      1.33|\n",
      "+--------------------+----------+------+----------+------+-----------+--------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select *from default.covid_data\").show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}